\chapter{Expressions}
\section{INPUT Analysis}
Compilers are programs which translate source language to a target language. The Source language can be a language like C,C++ or Lisp. The potential target languages are assembly languages , object code
for the microprocessors like intel x86, itanium or power pc. There are programs which translate java to C++ and Lisp to C. In such case , target language is another programming language. 

Any compiler has to understand the input. Once it has analyzed the input characters , it should convert the input into a form which is suitable for further processing. Any input has to be parsed before the object code translation. 

To Parse means to understand. The Parsing process works as follows
The characters are grouped together to find a token ( or a word ). Some examples of the tokens are'+','*',while , for , if etc. The module which reads character at a time and looks for legal token is called
a lexical analyzer or Lexer. 

The input from the Lexer is passed into a module which identifies whether a group of tokens form a valid expression or a statement in the program. The module which determines the validity of expressions is called a parser. Rather than doing a lexical scan for the entire input , the parser requests the next token from the lexical analyzer. They act as if they are co-routines.

To put everything together let us write a small program which acts a four function calculator. The calculator is capable of evaluating mathematical expressions which contains four basic arithmetical operators, paranthesis to group the expression and unary operators.

Given below is the Lexical Specifications of the calculator.
\lstset{style=csharp}
\begin{lstlisting}
TOK_PLUS: '+'
TOK_MUL: '*'
TOK_SUB: '-'
TOK_DIV: '/'
TOK_OPAREN: '('
TOK_CPAREN: ')'
TOK_DOUBLE: [0-9]+
\end{lstlisting}


The lexical specification we just saw can be converted into C\# as follows:
\lstset{style=csharp}
\begin{lstlisting}
// Enumeration for Tokens
public enum TOKEN {
	ILLEGAL_TOKEN = -1, // Not a Token
	TOK_PLUS = 1, // '+'
	TOK_MUL, // '*'
	TOK_DIV, // '/'
	TOK_SUB, // '-'
	TOK_OPAREN, // '('
	TOK_CPAREN, // ')'
	TOK_DOUBLE, // '('
	TOK_NULL // End of string
}
\end{lstlisting}
\clearpage
The Lexical Analysis Algorithm scans through the input and returns the token associated with the operator. If it has found out a number returns the token associated with the number. There should be another mechanism to retrieve the actual number identified.

Following pseudo code shows the schema of the lexical analyzer
\lstset{style=csharp}
\begin{lstlisting}
while ( there is input ) {
	switch(currentchar) {
		case Operands:
			advance input pointer
			return TOK_XXXX;
		case Number:
			Extract the number( Advance the input )
			return TOK_DOUBLE;
		default:
		error
	}
}
\end{lstlisting}
The following C\# code is a literal translation of the above algorithm.
\lstset{style=csharp}
\begin{lstlisting}
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
namespace SLANG_DOT_NET 
{
	// Enumeration for Tokens
	public enum TOKEN
	{
		ILLEGAL_TOKEN = -1, // Not a Token
		TOK_PLUS = 1, // '+'
		TOK_MUL, // '*'
		TOK_DIV, // '/'
		TOK_SUB, // '-'
		TOK_OPAREN, // '('
		TOK_CPAREN, // ')'
		TOK_DOUBLE, // '('
		TOK_NULL // End of string
	}


	// A naive Lexical analyzer which looks for 
	// operators , Parenthesis and number. 
	// All numbers are treated as IEEE doubles. Only numbers
	// without decimals can be entered. 
	// Feel free to modify the code
	// to accomodate LONG and Double values
	public class Lexer
	{
		String IExpr; // Expression string
		int index; // index into a character
		int length; // Length of the string
		double number; // Last grabbed number from the stream
		
		public Lexer(String Expr)
		{
			IExpr = Expr;
			length = IExpr.Length;
			index = 0;
		}

		// Grab the next token from the stream
		public TOKEN GetToken()
		{
			TOKEN tok = TOKEN.ILLEGAL_TOKEN;
			// Skip the white space
			while (index < length &&
				(IExpr[index] == ' ' || 
				IExpr[index] == '\t')) {
				index++;
			}
			// End of string ? return NULL;
			if (index == length) {
				return TOKEN.TOK_NULL;
			}

			switch (IExpr[index])
			{
				case '+':
				tok = TOKEN.TOK_PLUS;
				index++;
				break;
				
				case '-':
				tok = TOKEN.TOK_SUB;
				index++;
				break;
				
				case '/':
				tok = TOKEN.TOK_DIV;
				index++;
				break;
				
				case '*':
				tok = TOKEN.TOK_MUL;
				index++;
				break;
				
				case '(':
				tok = TOKEN.TOK_OPAREN;
				index++;
				break;
				
				case ')':
				tok = TOKEN.TOK_CPAREN;
				index++;
				break;
				
				case '0':
				case '1':
				case '2':
				case '3':
				case '4':
				case '5':
				case '6':
				case '7':
				case '8':
				case '9':
				{
					String str = "";
					while (index < length &&
					(IExpr[index] == '0' ||
					IExpr[index] == '1' ||
					IExpr[index] == '2' ||
					IExpr[index] == '3' ||
					IExpr[index] == '4' ||
					IExpr[index] == '5' ||
					IExpr[index] == '6' ||
					IExpr[index] == '7' ||
					IExpr[index] == '8' ||
					IExpr[index] == '9'))
					{
						str += 
							Convert.ToString(IExpr[index]);
						index++;
					}
					number = Convert.ToDouble(str);
					tok = TOKEN.TOK_DOUBLE;
				}
				break;
				
				default:
				Console.WriteLine("Error While Analyzing Tokens");
				throw new Exception();
			}
			return tok;
		}
		
		public double GetNumber() { return number; }
	}
}
\end{lstlisting}

\section{The Grammar}
In computer science, a formal grammar (or grammar) is a set of formation rules (grammar) that describe which strings formed from the alphabet of a formal language are syntactically valid within the language. A grammar only addresses the location and manipulation of the strings of the language. It does not describe anything else about a language, such as its semantics (i.e. what the strings mean).

A context-free grammar is a grammar in which the left-hand side of each production rule consists of only a single nonterminal symbol. This restriction is non-trivial; not all languages can be generated by context-free grammars. Those that can are called context-free languages.

The Backus Naur Form (BNF) notation is used to specify grammars for programming languages, commnd line tools, file formats to name a few . The semantics of BNF is beyond the scope of this book.

\subsection{Grammar of the expression evaluator}
\lstset{style=csharp}
\begin{lstlisting}
<Expr> ::= <Term> | <Term> { + | - } <Expr>
<Term> ::= <Factor> | <Factor> {* | /} <Term>
<Factor>::= <number> | ( <expr> ) | {+ | -} <factor>
\end{lstlisting}
There are two types of tokens in any grammar specifications. They are terminal tokens ( terminals ) or non terminals . In the above grammar , operators and \textless number\textgreater are the terminals.

\textless Expr\textgreater,\textless Term\textgreater,\textless Factor\textgreater are non terminals. Non terminals will have at least one entry on the left side. 


In the following three sections the pesudo code snippets for converting each of our non terminals is shown.
Note that they closely match with production rules we stated.
\section{Conversion of Expression}
\lstset{style=csharp}
\begin{lstlisting}
// <Expr> ::= <Term> { + | - } <Expr>
Void Expr() {
	Term();
	if ( Token == TOK_PLUS || Token == TOK_SUB )
	{
		// Emit instructions
		// and perform semantic operations
		Expr(); // recurse
	}
}
\end{lstlisting}

\section{Conversion of Term}
\lstset{style=csharp}
\begin{lstlisting}
// <Term> ::= <Factor> { * | / } <Term>
Void Term() {
	Factor();
	if ( Token == TOK_MUL || Token == TOK_DIV )
	{
		// Emit instructions
		// and perform semantic operations
		Term(); // recurse
	}
}
\end{lstlisting}

\section{Conversion of Factor}
\lstset{style=csharp}
\begin{lstlisting}
// <Factor> ::= <TOK_DOUBLE> | ( <expr> ) | { + |- } <Factor>
Void Factor() {
	switch(Token) {
		case TOK_DOUBLE:
		// push token to IL operand stack return
		
		case TOK_OPAREN:
		Expr(); //recurse
		// check for closing parenthesis and return

		case UNARYOP:
		Factor(); //recurse
		
		default:
		//Error
	}
}
\end{lstlisting}
\section{RD Parser}
The class RDParser is derived from the Lexer class. By using an algorithm by the name Recursive descent parsing , we will evaluate the expression.A recursive descent parser is a top-down parser built from a set of mutually-recursive procedures where each such procedure usually implements one of the production rules of the grammar. Thus the structure of the resulting program closely mirrors that of the grammar it recognizes.
\lstset{style=csharp}
\begin{lstlisting}
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
namespace SLANG_DOT_NET
{
	public class RDParser : Lexer
	{
		TOKEN Current_Token;
		public RDParser(String str)
		: base(str)
		{
		}
		
		public Exp CallExpr()
		{
			Current_Token = GetToken();
			return Expr();
		}
		
		public Exp Expr()
		{
			TOKEN l_token;
			Exp RetValue = Term();
			while (Current_Token == TOKEN.TOK_PLUS 
				|| Current_Token == TOKEN.TOK_SUB)
			{
				l_token = Current_Token;
				Current_Token = GetToken();
				Exp e1 = Expr();
				RetValue = new BinaryExp(RetValue, e1,
				l_token == 
				TOKEN.TOK_PLUS ? 
				OPERATOR.PLUS : OPERATOR.MINUS);
			}
			return RetValue;
		}

		public Exp Term()
		{
			TOKEN l_token;
			Exp RetValue = Factor();
			while (Current_Token == TOKEN.TOK_MUL 
				|| Current_Token == TOKEN.TOK_DIV)
			{
				l_token = Current_Token;
				Current_Token = GetToken();
				Exp e1 = Term();
				RetValue = 
				new BinaryExp(RetValue, e1,
				l_token == 
				TOKEN.TOK_MUL ? 
				OPERATOR.MUL : OPERATOR.DIV);
			}
			return RetValue;
		}

		public Exp Factor()
		{
			TOKEN l_token;
			Exp RetValue = null;
			if (Current_Token == TOKEN.TOK_DOUBLE)
			{
				RetValue = new NumericConstant(GetNumber());
				Current_Token = GetToken();
			}
			else if (Current_Token == TOKEN.TOK_OPAREN)
			{
				Current_Token = GetToken();
				RetValue = Expr(); // Recurse
				if (Current_Token != TOKEN.TOK_CPAREN)
				{
					Console.WriteLine("Missing Closing Parenthesis");
					throw new Exception();
				}
				Current_Token = GetToken();
			}
			else if (Current_Token == TOKEN.TOK_PLUS 
				|| Current_Token == TOKEN.TOK_SUB)
			{
				l_token = Current_Token;
				Current_Token = GetToken();
				RetValue = Factor();
				RetValue = 
				new UnaryExp(RetValue,
				l_token == TOKEN.TOK_PLUS ? 
				OPERATOR.PLUS : OPERATOR.MINUS);
			}
			else
			{
				Console.WriteLine("Illegal Token");
				throw new Exception();
			}
			return RetValue;
		}
	} 	
}
\end{lstlisting}

\section{Builder}
Using the Builder Pattern , we will encapsulate the Parser , Lexer class activities
\lstset{style=csharp}
\begin{lstlisting}
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
namespace SLANG_DOT_NET
{
	// Base class for all the Builders
	public class AbstractBuilder
	{
	}

	public class ExpressionBuilder : AbstractBuilder
	{
		public string _expr_string;
		public ExpressionBuilder(string expr)
		{
			_expr_string = expr;
		}
		
		public Exp GetExpression()
		{
			try
			{
				RDParser p = 
				new RDParser(_expr_string);
				return p.CallExpr();
			}
			catch (Exception)
			{
				return null;
			}
		}
	}
}
\end{lstlisting}

\section{Main}
In the CallSLang Project , the expression compiler is invoked as follows
\lstset{style=csharp}
\begin{lstlisting}
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using SLANG_DOT_NET;
namespace CallSLANG
{
	class Program
	{
		static void Main(string[] args)
		{
			ExpressionBuilder b = new ExpressionBuilder("-2*(3+3)");
			Exp e = b.GetExpression();
			Console.WriteLine(e.Evaluate(null));
			Console.Read();
		}
	} 
}
\end{lstlisting}